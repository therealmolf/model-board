{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import grad\n",
    "from sklearn import linear_model\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For consistent results\n",
    "t.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "- [ ] Look for basic datasets (or use toy datasets first)\n",
    "- [ ] Turn this into a Torch Dataset\n",
    "- [ ] Access Torch Dataset via Dataloaders\n",
    "- [ ] Do everything similarly using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying out matmul with grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tensor pertaining to input: \n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5190</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5678</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2385</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6783</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5204</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9234</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4720</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5877</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3210</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2898</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">requires_grad</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tensor pertaining to input: \n",
       " \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.5190\u001b[0m, \u001b[1;36m-0.5678\u001b[0m, \u001b[1;36m-0.2385\u001b[0m, \u001b[1;36m-0.6783\u001b[0m,  \u001b[1;36m0.5204\u001b[0m, \u001b[1;36m-0.9234\u001b[0m,  \u001b[1;36m1.4720\u001b[0m, \u001b[1;36m-0.5877\u001b[0m,\n",
       "        \u001b[1;36m-0.3210\u001b[0m,  \u001b[1;36m0.2898\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m, \u001b[33mrequires_grad\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tensor pertaining to weights: \n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3764</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3801</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2915</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5394</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8064</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8145</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3347</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2936</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3256</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9996</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">requires_grad</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tensor pertaining to weights: \n",
       " \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3764\u001b[0m, \u001b[1;36m0.3801\u001b[0m, \u001b[1;36m0.2915\u001b[0m, \u001b[1;36m0.5394\u001b[0m, \u001b[1;36m0.8064\u001b[0m, \u001b[1;36m0.8145\u001b[0m, \u001b[1;36m0.3347\u001b[0m, \u001b[1;36m0.2936\u001b[0m, \u001b[1;36m0.3256\u001b[0m,\n",
       "        \u001b[1;36m0.9996\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m, \u001b[33mrequires_grad\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tensor pertaining to bias: \n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tensor pertaining to bias: \n",
       " \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.1000\u001b[0m,\n",
       "        \u001b[1;36m0.1000\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = t.randn(10, requires_grad=True, device=device)\n",
    "weights = t.rand(10, requires_grad=True, device=device)\n",
    "# small positive initialization\n",
    "bias = t.ones(10, device=device) * 0.1\n",
    "\n",
    "print(f\"Tensor pertaining to input: \\n {x}\")\n",
    "print(f\"Tensor pertaining to weights: \\n {weights}\")\n",
    "print(f\"Tensor pertaining to bias: \\n {bias}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1935</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1935\u001b[0m, \u001b[1;36m0.1935\u001b[0m,\n",
       "        \u001b[1;36m0.1935\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5482</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SigmoidBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.5482\u001b[0m, \u001b[1;36m0.5482\u001b[0m, \u001b[1;36m0.5482\u001b[0m, \u001b[1;36m0.5482\u001b[0m, \u001b[1;36m0.5482\u001b[0m, \u001b[1;36m0.5482\u001b[0m, \u001b[1;36m0.5482\u001b[0m, \u001b[1;36m0.5482\u001b[0m, \u001b[1;36m0.5482\u001b[0m,\n",
       "        \u001b[1;36m0.5482\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSigmoidBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = x @ weights + bias\n",
    "activated_z = t.sigmoid(z)\n",
    "# loss = F.binary_cross_entropy()\n",
    "# compute grad\n",
    "\n",
    "print(z)\n",
    "print(activated_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The batch size is: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The batch size is: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The input dim is: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The input dim is: \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    batch: int = 5\n",
    "    input_dim: int = 10\n",
    "    output_dim: int = 1\n",
    "    device: t.device = device\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "print(f\"The batch size is: {cfg.batch}\")\n",
    "print(f\"The input dim is: {cfg.input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3391</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6843</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6086</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6359</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3607</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3391\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.6843\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.6086\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.6359\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.3607\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cu\u001b[1;92mda:0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class LogisticRegression(t.nn.Module):\n",
    "    '''\n",
    "        Simple LogisticRegression using PyTorch \n",
    "    '''\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.linear = t.nn.Linear(self.cfg.input_dim, self.cfg.output_dim, device=self.cfg.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probs = t.sigmoid(logits)\n",
    "        \n",
    "        return probs\n",
    "\n",
    "\n",
    "x = t.randn((cfg.batch, cfg.input_dim), device=cfg.device)\n",
    "model = LogisticRegression(cfg)\n",
    "\n",
    "with t.inference_mode():\n",
    "    output = model(x)\n",
    "    print(output)\n",
    "    print(output.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSEUDO PSEUDO CODE\n",
    "# loop through epochs\n",
    "# loop through batches of dataloader\n",
    "# get outputs, get loss, zero grad, backprop, optimizer step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using Sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-board",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
