{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I want to see the differences in:\n",
    "* Speed\n",
    "* Verbosity\n",
    "\n",
    "when computing with:\n",
    "* For loops\n",
    "* PyTorch Tensors\n",
    "* Einops\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from dataclasses import dataclass\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu121'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Benchmarking\n",
    "---\n",
    "Comparing differences between using Tensor methods vs. @. According to online resources, @ operates faster especially for larger tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0607)\n",
      "tensor(0.0607)\n",
      "tensor([-0.1744,  7.5032, -4.4844,  4.0740,  0.0352])\n",
      "tensor([-0.1744,  7.5032, -4.4844,  4.0740,  0.0352])\n"
     ]
    }
   ],
   "source": [
    "A = t.randn(10)\n",
    "B = t.randn(10)\n",
    "C = t.randn((5, 10))\n",
    "\n",
    "print(A @ B)\n",
    "print(A.dot(B))\n",
    "print(C @ A)\n",
    "print(C.matmul(A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.06 µs ± 175 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A.dot(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.39 µs ± 91.2 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Perceptron Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    batch_size: int = 150\n",
    "    dim: int = 50\n",
    "    bias: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7161, 0.8991, 0.1289, 0.9035, 0.7489, 0.6061, 0.9852, 0.6685, 0.6255,\n",
       "        0.9706, 0.8243, 0.1047, 0.9029, 0.5215, 0.5192, 0.9593, 0.2049, 0.3035,\n",
       "        0.1134, 0.7873, 0.4234, 0.6672, 0.9633, 0.6437, 0.6667, 0.6866, 0.3409,\n",
       "        0.6675, 0.1333, 0.7062, 0.9062, 0.0141, 0.3397, 0.7208, 0.8370, 0.8042,\n",
       "        0.8269, 0.0795, 0.0271, 0.3421, 0.2195, 0.8257, 0.6976, 0.7046, 0.9519,\n",
       "        0.7407, 0.7738, 0.7141, 0.3958, 0.6465])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = Config()\n",
    "\n",
    "t.rand(cfg.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.dim = self.cfg.dim\n",
    "        self.weights = t.rand(self.dim)\n",
    "        self.bias = self.cfg.bias\n",
    "    \n",
    "    def forward(self, x: t.Tensor):\n",
    "        return x @ self.weights + self.bias\n",
    "\n",
    "    def update(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "model = Perceptron(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.rand((cfg.batch_size, cfg.dim))\n",
    "\n",
    "model.forward(x).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-board",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
