{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operations on PyTorch and Einops\n",
    "---\n",
    "Just comparing syntactical differences between vanilla Torch operations vs. Einops. Additionally, I used different options to perform matmul for a minimal Perceptron implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import einops as eo\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Benchmarking\n",
    "---\n",
    "Comparing differences between using Tensor methods vs. @. According to online resources, @ operates faster especially for larger tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.5933)\n",
      "tensor(-3.5933)\n",
      "tensor([-1.0633,  3.0227, -0.0661, -1.8092, -5.4111])\n",
      "tensor([-1.0633,  3.0227, -0.0661, -1.8092, -5.4111])\n"
     ]
    }
   ],
   "source": [
    "A = t.randn(10)\n",
    "B = t.randn(10)\n",
    "C = t.randn((5, 10))\n",
    "\n",
    "print(A @ B)\n",
    "print(A.dot(B))\n",
    "print(C @ A)\n",
    "print(C.matmul(A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73 µs ± 169 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A.dot(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.46 µs ± 248 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image = t.randint(0, 255, (96, 96, 3), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_np_img = np.random.randint(255, size=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eo.rearrange(fake_np_img, 'h w c -> w h c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "eo.rearrange(fake_np_img, 'h w c -> (h w c)').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Perceptron Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    batch_size: int = 150\n",
    "    dim: int = 50\n",
    "    bias: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1617e-01, 2.9531e-01, 8.1326e-01, 5.2690e-01, 4.7365e-01, 6.9079e-01,\n",
       "        4.7149e-01, 2.1553e-01, 6.7955e-01, 9.4254e-01, 6.1680e-01, 8.3811e-01,\n",
       "        8.3989e-01, 3.6920e-01, 5.6553e-01, 8.4530e-01, 2.1171e-01, 3.0843e-01,\n",
       "        1.7100e-01, 3.0391e-01, 8.4071e-01, 6.1277e-01, 9.4606e-01, 9.4990e-01,\n",
       "        9.7225e-01, 9.7965e-01, 5.6676e-01, 9.8509e-02, 4.5395e-01, 9.0738e-02,\n",
       "        1.9128e-01, 4.3274e-01, 6.5174e-01, 8.4323e-04, 1.8355e-01, 3.4983e-01,\n",
       "        2.6994e-01, 8.1129e-01, 8.4119e-01, 3.5221e-01, 1.3352e-01, 1.4109e-01,\n",
       "        2.0150e-01, 1.4824e-01, 9.8783e-01, 5.3288e-01, 3.1903e-02, 2.0534e-01,\n",
       "        4.2547e-01, 9.7368e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = Config()\n",
    "\n",
    "t.rand(cfg.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.dim = self.cfg.dim\n",
    "        self.weights = t.rand(self.dim)\n",
    "        self.bias = self.cfg.bias\n",
    "    \n",
    "    def forward(self, x: t.Tensor):\n",
    "        # Still need to add the threshold function\n",
    "        return x @ self.weights + self.bias\n",
    "\n",
    "    def update(self):\n",
    "        # piece-wise that works directly on error\n",
    "        pass\n",
    "\n",
    "\n",
    "model = Perceptron(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.rand((cfg.batch_size, cfg.dim))\n",
    "\n",
    "model.forward(x).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-board",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
